{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df54e21-f172-45ce-94e4-f7904155fd22",
   "metadata": {},
   "source": [
    "# $$Step\\ 7 : Lemmatization$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435b12aa-fcd4-4340-b1cd-30302fade33a",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7588b42-4d42-4441-b742-7cc73caf2595",
   "metadata": {},
   "source": [
    "# **Text Preprocessing: Lemmatization vs. Stemming in NLP**\n",
    "\n",
    "## **1Ô∏è‚É£ What is Lemmatization?**\n",
    "Lemmatization is a text preprocessing technique used in **Natural Language Processing (NLP)** to reduce words to their base or **dictionary form** (lemma) while preserving their meaning.  \n",
    "\n",
    "Unlike **Stemming**, which cuts off word endings, **Lemmatization** uses a **predefined dictionary** to ensure the root form of the word is meaningful.\n",
    "\n",
    "### **üîπ Example Comparison**\n",
    "| Word        | Stemming   | Lemmatization |\n",
    "|------------|-----------|--------------|\n",
    "| running    | run       | run          |\n",
    "| connected  | connect   | connect      |\n",
    "| better     | better    | good         |\n",
    "| studies    | studi     | study        |\n",
    "| worse      | wors      | worse        |\n",
    "\n",
    "üìå **Key Difference:**  \n",
    "- **Stemming:** Chops off word endings and may produce meaningless words.  \n",
    "- **Lemmatization:** Returns the **dictionary base form**, ensuring meaningful words.\n",
    "\n",
    "---\n",
    "\n",
    "## **2Ô∏è‚É£ Why Use Lemmatization?**\n",
    "‚úî **Better Accuracy:** Produces correct words instead of cutting off characters randomly.  \n",
    "‚úî **Reduces Vocabulary Size:** Groups different forms of a word (e.g., \"studying\" ‚Üí \"study\").  \n",
    "‚úî **Important for Sentiment Analysis:** Helps understand words correctly in context.\n",
    "\n",
    "‚ö† **Limitation:** Lemmatization is **slower** than stemming because it uses a dictionary lookup.\n",
    "\n",
    "---\n",
    "\n",
    "## **3Ô∏è‚É£ Implementing Stemming and Lemmatization in Python**\n",
    "We will compare both techniques using the **NLTK** library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a9fcdc-30a4-414b-b447-8d16e2e1bdf3",
   "metadata": {},
   "source": [
    "_____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c57b269-71c3-4292-95a2-559c9678a70b",
   "metadata": {},
   "source": [
    "### Exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090c919c-dd62-40a6-92b8-2113dcd75ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f66fa5f-6fa1-475d-b4dd-107c4c64361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  :  running\n",
      "connected  :  connected\n",
      "better  :  better\n",
      "studies  :  study\n",
      "dogs  :  dog\n",
      "happily  :  happily\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# create lemmatizer \n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "# Sample words to process\n",
    "words = [\"running\", \"connected\", \"better\", \"studies\", \"dogs\", \"happily\"]\n",
    "\n",
    "for x in words :\n",
    "    print(x , \" : \" , lem.lemmatize(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89f9523-3447-44e0-8235-711b331fb40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  :  run\n",
      "connected  :  connect\n",
      "better  :  better\n",
      "studies  :  studi\n",
      "dogs  :  dog\n",
      "happily  :  happili\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Create a stemmer \n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Sample words to process\n",
    "words = [\"running\", \"connected\", \"better\", \"studies\", \"dogs\", \"happily\"]\n",
    "\n",
    "for x in words :\n",
    "    print( x , \" : \" , ps.stem(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eb76b9-811f-4c46-94eb-8825788ff306",
   "metadata": {},
   "source": [
    "### Exemple : Lemmatization in Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb180465-9852-4d2b-96e7-21db5c730d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The food was amazing, and I enjoyed it!\n",
      "Lemmatized: The food wa amazing , and I enjoyed it !\n",
      "\n",
      "Original: I loved the experience of dining here.\n",
      "Lemmatized: I loved the experience of dining here .\n",
      "\n",
      "Original: The service was the worst I have ever seen!\n",
      "Lemmatized: The service wa the worst I have ever seen !\n",
      "\n",
      "Original: The atmosphere was relaxing and pleasant.\n",
      "Lemmatized: The atmosphere wa relaxing and pleasant .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = [\n",
    "    \"The food was amazing, and I enjoyed it!\",\n",
    "    \"I loved the experience of dining here.\",\n",
    "    \"The service was the worst I have ever seen!\",\n",
    "    \"The atmosphere was relaxing and pleasant.\"\n",
    "]\n",
    "\n",
    "# Tokenize and lemmatize words in reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "lemmatized_reviews = []\n",
    "for review in reviews:\n",
    "    words = word_tokenize(review)  # Tokenize words\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]  # Apply lemmatization\n",
    "    lemmatized_reviews.append(\" \".join(lemmatized_words))  # Reconstruct sentences\n",
    "\n",
    "# Print results\n",
    "for original, lemmatized in zip(reviews, lemmatized_reviews):\n",
    "    print(f\"Original: {original}\\nLemmatized: {lemmatized}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ddcc2-cf2a-4caf-acb9-e651fe5e9482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
